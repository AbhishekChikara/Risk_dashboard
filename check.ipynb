{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "784197bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "loadings_df = pd.read_csv(\"02_case_study_factor_loadings.csv\", skiprows=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5226a609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Beta</th>\n",
       "      <th>Dividend Yield</th>\n",
       "      <th>Earnings Yield</th>\n",
       "      <th>Excess Beta</th>\n",
       "      <th>Growth</th>\n",
       "      <th>Leverage</th>\n",
       "      <th>Liquidity</th>\n",
       "      <th>Market</th>\n",
       "      <th>Mid Cap</th>\n",
       "      <th>Momentum</th>\n",
       "      <th>Quality</th>\n",
       "      <th>Semiconductors</th>\n",
       "      <th>Size</th>\n",
       "      <th>Value</th>\n",
       "      <th>Volatility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9/29/2022</td>\n",
       "      <td>2.08</td>\n",
       "      <td>-0.76</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.38</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.54</td>\n",
       "      <td>-0.69</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>1</td>\n",
       "      <td>0.89</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>-0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9/30/2022</td>\n",
       "      <td>2.07</td>\n",
       "      <td>-0.76</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.38</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>1</td>\n",
       "      <td>0.89</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>-0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10/3/2022</td>\n",
       "      <td>2.07</td>\n",
       "      <td>-0.76</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.41</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>-1.03</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>1</td>\n",
       "      <td>0.89</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>-0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10/4/2022</td>\n",
       "      <td>2.01</td>\n",
       "      <td>-0.76</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.41</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>-1.06</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>-0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/5/2022</td>\n",
       "      <td>2.01</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.41</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>-1.07</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>1</td>\n",
       "      <td>0.89</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>-0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>9/24/2025</td>\n",
       "      <td>1.39</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>-0.91</td>\n",
       "      <td>1.22</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>0.66</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>1.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>-0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>9/25/2025</td>\n",
       "      <td>1.38</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>-0.94</td>\n",
       "      <td>1.21</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>0.66</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>1.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>-0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>9/26/2025</td>\n",
       "      <td>1.38</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>-0.95</td>\n",
       "      <td>1.22</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>0.66</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>-0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>9/29/2025</td>\n",
       "      <td>1.38</td>\n",
       "      <td>-0.57</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>-0.95</td>\n",
       "      <td>1.22</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>0.66</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>-0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>9/30/2025</td>\n",
       "      <td>1.40</td>\n",
       "      <td>-0.57</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>-0.94</td>\n",
       "      <td>1.22</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>0.66</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>-0.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>753 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  Beta  Dividend Yield  Earnings Yield  Excess Beta  Growth  \\\n",
       "0    9/29/2022  2.08           -0.76           -0.27         0.33    0.38   \n",
       "1    9/30/2022  2.07           -0.76           -0.27         0.30    0.38   \n",
       "2    10/3/2022  2.07           -0.76           -0.28         0.34    0.41   \n",
       "3    10/4/2022  2.01           -0.76           -0.28         0.08    0.41   \n",
       "4    10/5/2022  2.01           -0.75           -0.28         0.06    0.41   \n",
       "..         ...   ...             ...             ...          ...     ...   \n",
       "748  9/24/2025  1.39           -0.58           -0.19        -0.91    1.22   \n",
       "749  9/25/2025  1.38           -0.58           -0.19        -0.94    1.21   \n",
       "750  9/26/2025  1.38           -0.58           -0.19        -0.95    1.22   \n",
       "751  9/29/2025  1.38           -0.57           -0.19        -0.95    1.22   \n",
       "752  9/30/2025  1.40           -0.57           -0.19        -0.94    1.22   \n",
       "\n",
       "     Leverage  Liquidity  Market  Mid Cap  Momentum  Quality  Semiconductors  \\\n",
       "0       -0.48       1.26       1    -0.54     -0.69    -0.42               1   \n",
       "1       -0.48       1.25       1    -0.55     -0.75    -0.41               1   \n",
       "2       -0.48       1.25       1    -0.55     -1.03    -0.41               1   \n",
       "3       -0.48       1.25       1    -0.55     -1.06    -0.40               1   \n",
       "4       -0.48       1.25       1    -0.55     -1.07    -0.40               1   \n",
       "..        ...        ...     ...      ...       ...      ...             ...   \n",
       "748     -0.58       0.66       1    -0.52      1.07     0.00               1   \n",
       "749     -0.58       0.66       1    -0.52      1.07     0.00               1   \n",
       "750     -0.58       0.66       1    -0.52      1.06     0.00               1   \n",
       "751     -0.58       0.66       1    -0.52      0.99     0.01               1   \n",
       "752     -0.58       0.66       1    -0.52      0.89     0.01               1   \n",
       "\n",
       "     Size  Value  Volatility  \n",
       "0    0.89  -0.48       -0.80  \n",
       "1    0.89  -0.49       -0.79  \n",
       "2    0.89  -0.48       -0.79  \n",
       "3    0.90  -0.49       -0.79  \n",
       "4    0.89  -0.48       -0.79  \n",
       "..    ...    ...         ...  \n",
       "748  0.84  -0.43       -0.67  \n",
       "749  0.84  -0.43       -0.67  \n",
       "750  0.84  -0.43       -0.67  \n",
       "751  0.84  -0.43       -0.68  \n",
       "752  0.84  -0.42       -0.68  \n",
       "\n",
       "[753 rows x 16 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loadings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be02210f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loadings_df = pd.read_csv(\"02_case_study_factor_loadings.csv\") # Try without skiprows if error occurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd29cd9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NVDA Daily Factor Loadings</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "      <th>Unnamed: 14</th>\n",
       "      <th>Unnamed: 15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Date</td>\n",
       "      <td>Beta</td>\n",
       "      <td>Dividend Yield</td>\n",
       "      <td>Earnings Yield</td>\n",
       "      <td>Excess Beta</td>\n",
       "      <td>Growth</td>\n",
       "      <td>Leverage</td>\n",
       "      <td>Liquidity</td>\n",
       "      <td>Market</td>\n",
       "      <td>Mid Cap</td>\n",
       "      <td>Momentum</td>\n",
       "      <td>Quality</td>\n",
       "      <td>Semiconductors</td>\n",
       "      <td>Size</td>\n",
       "      <td>Value</td>\n",
       "      <td>Volatility</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9/29/2022</td>\n",
       "      <td>2.08</td>\n",
       "      <td>-0.76</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.38</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.54</td>\n",
       "      <td>-0.69</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>1</td>\n",
       "      <td>0.89</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>-0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9/30/2022</td>\n",
       "      <td>2.07</td>\n",
       "      <td>-0.76</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.38</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>1</td>\n",
       "      <td>0.89</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>-0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/3/2022</td>\n",
       "      <td>2.07</td>\n",
       "      <td>-0.76</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.41</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>-1.03</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>1</td>\n",
       "      <td>0.89</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>-0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>9/24/2025</td>\n",
       "      <td>1.39</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>-0.91</td>\n",
       "      <td>1.22</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>0.66</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>1.07</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>-0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>9/25/2025</td>\n",
       "      <td>1.38</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>-0.94</td>\n",
       "      <td>1.21</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>0.66</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>1.07</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>-0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>9/26/2025</td>\n",
       "      <td>1.38</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>-0.95</td>\n",
       "      <td>1.22</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>0.66</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>-0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>9/29/2025</td>\n",
       "      <td>1.38</td>\n",
       "      <td>-0.57</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>-0.95</td>\n",
       "      <td>1.22</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>0.66</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>-0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>9/30/2025</td>\n",
       "      <td>1.4</td>\n",
       "      <td>-0.57</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>-0.94</td>\n",
       "      <td>1.22</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>0.66</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>-0.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>755 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    NVDA Daily Factor Loadings Unnamed: 1      Unnamed: 2      Unnamed: 3  \\\n",
       "0                          NaN        NaN             NaN             NaN   \n",
       "1                         Date       Beta  Dividend Yield  Earnings Yield   \n",
       "2                    9/29/2022       2.08           -0.76           -0.27   \n",
       "3                    9/30/2022       2.07           -0.76           -0.27   \n",
       "4                    10/3/2022       2.07           -0.76           -0.28   \n",
       "..                         ...        ...             ...             ...   \n",
       "750                  9/24/2025       1.39           -0.58           -0.19   \n",
       "751                  9/25/2025       1.38           -0.58           -0.19   \n",
       "752                  9/26/2025       1.38           -0.58           -0.19   \n",
       "753                  9/29/2025       1.38           -0.57           -0.19   \n",
       "754                  9/30/2025        1.4           -0.57           -0.19   \n",
       "\n",
       "      Unnamed: 4 Unnamed: 5 Unnamed: 6 Unnamed: 7 Unnamed: 8 Unnamed: 9  \\\n",
       "0            NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "1    Excess Beta     Growth   Leverage  Liquidity     Market    Mid Cap   \n",
       "2           0.33       0.38      -0.48       1.26          1      -0.54   \n",
       "3            0.3       0.38      -0.48       1.25          1      -0.55   \n",
       "4           0.34       0.41      -0.48       1.25          1      -0.55   \n",
       "..           ...        ...        ...        ...        ...        ...   \n",
       "750        -0.91       1.22      -0.58       0.66          1      -0.52   \n",
       "751        -0.94       1.21      -0.58       0.66          1      -0.52   \n",
       "752        -0.95       1.22      -0.58       0.66          1      -0.52   \n",
       "753        -0.95       1.22      -0.58       0.66          1      -0.52   \n",
       "754        -0.94       1.22      -0.58       0.66          1      -0.52   \n",
       "\n",
       "    Unnamed: 10 Unnamed: 11     Unnamed: 12 Unnamed: 13 Unnamed: 14  \\\n",
       "0           NaN         NaN             NaN         NaN         NaN   \n",
       "1      Momentum     Quality  Semiconductors        Size       Value   \n",
       "2         -0.69       -0.42               1        0.89       -0.48   \n",
       "3         -0.75       -0.41               1        0.89       -0.49   \n",
       "4         -1.03       -0.41               1        0.89       -0.48   \n",
       "..          ...         ...             ...         ...         ...   \n",
       "750        1.07           0               1        0.84       -0.43   \n",
       "751        1.07           0               1        0.84       -0.43   \n",
       "752        1.06           0               1        0.84       -0.43   \n",
       "753        0.99        0.01               1        0.84       -0.43   \n",
       "754        0.89        0.01               1        0.84       -0.42   \n",
       "\n",
       "    Unnamed: 15  \n",
       "0           NaN  \n",
       "1    Volatility  \n",
       "2          -0.8  \n",
       "3         -0.79  \n",
       "4         -0.79  \n",
       "..          ...  \n",
       "750       -0.67  \n",
       "751       -0.67  \n",
       "752       -0.67  \n",
       "753       -0.68  \n",
       "754       -0.68  \n",
       "\n",
       "[755 rows x 16 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loadings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d067e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    earnings_df = pd.read_csv(\"03_case_study_earnings_dates.csv\", skiprows=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6dd015ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NVDA Earnings Release Dates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11/16/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2/22/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5/24/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8/23/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11/21/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2/21/2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5/22/2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8/28/2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11/20/2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2/26/2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5/28/2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8/27/2025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NVDA Earnings Release Dates\n",
       "0                   11/16/2022\n",
       "1                    2/22/2023\n",
       "2                    5/24/2023\n",
       "3                    8/23/2023\n",
       "4                   11/21/2023\n",
       "5                    2/21/2024\n",
       "6                    5/22/2024\n",
       "7                    8/28/2024\n",
       "8                   11/20/2024\n",
       "9                    2/26/2025\n",
       "10                   5/28/2025\n",
       "11                   8/27/2025"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earnings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3831399",
   "metadata": {},
   "outputs": [],
   "source": [
    "AIzaSyB7t74zOUjWZk5qnKcqTh3Q7xj1Bm9P9dQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7910f15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "# --- Page Config ---\n",
    "st.set_page_config(layout=\"wide\", page_title=\"KR Capital: Earnings Dashboard\")\n",
    "\n",
    "# --- Dynamic Stock Folder Logic ---\n",
    "def get_stock_list(path='res'):\n",
    "    \"\"\"Scans for subdirectories which are assumed to be stock tickers.\"\"\"\n",
    "    return [d for d in os.listdir(path) if os.path.isdir(os.path.join(path, d)) and not d.startswith('.')]\n",
    "\n",
    "# --- Data Loading Functions ---\n",
    "@st.cache_data\n",
    "def load_data(stock_folder):\n",
    "    \"\"\"Loads data for a specific stock from its folder.\"\"\"\n",
    "    base_path = os.path.join('res', stock_folder)\n",
    "\n",
    "    # Load Returns\n",
    "    try:\n",
    "        returns_df = pd.read_csv(os.path.join(base_path, \"01_case_study_returns.csv\"), skiprows=2)\n",
    "    except:\n",
    "        returns_df = pd.read_csv(os.path.join(base_path, \"01_case_study_returns.csv\"))\n",
    "    returns_df['Date'] = pd.to_datetime(returns_df['Date'], format='%m/%d/%y', errors='coerce')\n",
    "    returns_df = returns_df.dropna(subset=['Date'])\n",
    "    \n",
    "    # Load Loadings\n",
    "    try:\n",
    "        loadings_df = pd.read_csv(os.path.join(base_path, \"02_case_study_factor_loadings.csv\"), skiprows=2)\n",
    "    except:\n",
    "        loadings_df = pd.read_csv(os.path.join(base_path, \"02_case_study_factor_loadings.csv\"))\n",
    "    loadings_df['Date'] = pd.to_datetime(loadings_df['Date'], format='mixed', errors='coerce')\n",
    "    loadings_df = loadings_df.dropna(subset=['Date'])\n",
    "\n",
    "    # Load Earnings Dates\n",
    "    try:\n",
    "        earnings_df = pd.read_csv(os.path.join(base_path, \"03_case_study_earnings_dates.csv\"), skiprows=2)\n",
    "    except:\n",
    "        earnings_df = pd.read_csv(os.path.join(base_path, \"03_case_study_earnings_dates.csv\"))\n",
    "\n",
    "    # Extract the first column regardless of name and clean it\n",
    "    earnings_df = earnings_df.iloc[:, 0].to_frame(name='Earnings Date')\n",
    "    earnings_df['Earnings Date'] = pd.to_datetime(earnings_df['Earnings Date'], errors='coerce')\n",
    "    earnings_df = earnings_df.dropna()\n",
    "    \n",
    "    return returns_df, loadings_df, earnings_df\n",
    "\n",
    "# --- Data Processing ---\n",
    "def process_data(returns_df, loadings_df, stock_ticker):\n",
    "    # Ensure column names are clean\n",
    "    returns_df.columns = returns_df.columns.str.strip()\n",
    "    loadings_df.columns = loadings_df.columns.str.strip()\n",
    "\n",
    "    # Merge Returns and Loadings\n",
    "    df = pd.merge(returns_df, loadings_df, on='Date', suffixes=('_Ret', '_Load'))\n",
    "    \n",
    "    # Identify Factor Columns\n",
    "    base_cols = [c.replace('_Ret', '') for c in df.columns if '_Ret' in c and stock_ticker not in c and 'Date' not in c]\n",
    "    \n",
    "    # Calculate Factor Contribution\n",
    "    df['Factor_Return'] = 0.0\n",
    "    for col in base_cols:\n",
    "        ret_col = f\"{col}_Ret\"\n",
    "        load_col = f\"{col}_Load\"\n",
    "        if ret_col in df.columns and load_col in df.columns:\n",
    "            df[f'Contrib_{col}'] = df[ret_col] * df[load_col]\n",
    "            df['Factor_Return'] += df[f'Contrib_{col}']\n",
    "            \n",
    "    # Calculate Idiosyncratic Return (Alpha)\n",
    "    df['Idiosyncratic_Return'] = df[stock_ticker] - df['Factor_Return']\n",
    "    \n",
    "    return df, base_cols\n",
    "\n",
    "# --- Event Study Logic ---\n",
    "def get_event_window(df, earnings_date, window_days=5):\n",
    "    try:\n",
    "        df = df.sort_values('Date').reset_index(drop=True)\n",
    "        idx_list = df.index[df['Date'] == earnings_date].tolist()\n",
    "        \n",
    "        if not idx_list:\n",
    "            return None\n",
    "            \n",
    "        t0_idx = idx_list[0]\n",
    "        \n",
    "        start_idx = max(0, t0_idx - window_days)\n",
    "        end_idx = min(len(df) - 1, t0_idx + window_days + 1)\n",
    "        \n",
    "        window_df = df.iloc[start_idx:end_idx].copy()\n",
    "        window_df['Rel_Day'] = window_df.index - t0_idx\n",
    "        \n",
    "        return window_df\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "# --- Plotly Waterfall Chart Function ---\n",
    "def create_waterfall(row, factor_cols, title):\n",
    "    factors = {col: row[f'Contrib_{col}'] for col in factor_cols}\n",
    "    sorted_factors = dict(sorted(factors.items(), key=lambda item: abs(item[1]), reverse=True))\n",
    "    \n",
    "    top_n = 5\n",
    "    wf_labels = ['Idiosyncratic (Alpha)'] + list(sorted_factors.keys())[:top_n] + ['Other Factors']\n",
    "    wf_values = [row['Idiosyncratic_Return']] + list(sorted_factors.values())[:top_n]\n",
    "    \n",
    "    other_sum = sum(list(sorted_factors.values())[top_n:])\n",
    "    wf_values.append(other_sum)\n",
    "\n",
    "    fig = go.Figure(go.Waterfall(\n",
    "        name = \"Return Attribution\", orientation = \"v\",\n",
    "        measure = [\"relative\"] * len(wf_values) + [\"total\"],\n",
    "        x = wf_labels + [\"Total Return\"],\n",
    "        textposition = \"outside\",\n",
    "        textfont_size=10, \n",
    "        text = [f\"{v:.1%}\" for v in wf_values + [sum(wf_values)]],\n",
    "        y = wf_values + [0],\n",
    "        connector = {\"line\":{\"color\":\"rgb(63, 63, 63)\"}},\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title = title,\n",
    "        showlegend = False,\n",
    "        yaxis_tickformat = '.1%',\n",
    "        height=500\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "# --- AI Summary Function ---\n",
    "def generate_ai_summary(api_key, stock_ticker, full_df, reaction_days, latest_reaction, second_latest_reaction, factor_cols):\n",
    "    try:\n",
    "        genai.configure(api_key=api_key)\n",
    "        model = genai.GenerativeModel('gemini-pro-latest') # Updated model name for general access\n",
    "    except Exception as e:\n",
    "        return f\"Error configuring AI model. Please check your API key. Details: {e}\"\n",
    "\n",
    "    avg_abs_move = reaction_days[stock_ticker].abs().mean()\n",
    "    avg_idio_move = reaction_days['Idiosyncratic_Return'].abs().mean()\n",
    "    corr_t1 = reaction_days[stock_ticker].corr(reaction_days['Idiosyncratic_Return'])\n",
    "    up_moves = (reaction_days[stock_ticker] > 0).sum()\n",
    "    total_moves = len(reaction_days)\n",
    "    \n",
    "    # Data for Tab 2 (Comparison)\n",
    "    second_latest_return = second_latest_reaction.iloc[0][stock_ticker] if not second_latest_reaction.empty else 'N/A'\n",
    "    second_latest_alpha = second_latest_reaction.iloc[0]['Idiosyncratic_Return'] if not second_latest_reaction.empty else 'N/A'\n",
    "\n",
    "    latest_row = latest_reaction.iloc[0]\n",
    "    latest_date = latest_row['Date'].strftime('%Y-%m-%d')\n",
    "    latest_return = latest_row[stock_ticker]\n",
    "    latest_idio = latest_row['Idiosyncratic_Return']\n",
    "    latest_factor_return = latest_row['Factor_Return']\n",
    "    \n",
    "    factors = {col: latest_row[f'Contrib_{col}'] for col in factor_cols}\n",
    "    sorted_factors = dict(sorted(factors.items(), key=lambda item: item[1], reverse=True))\n",
    "    top_3_pos = {k: v for k, v in sorted_factors.items() if v > 0 and k != 'Idiosyncratic (Alpha)'[:3]}\n",
    "    top_3_neg = {k: v for k, v in sorted(factors.items(), key=lambda item: item[1]) if v < 0 and k != 'Idiosyncratic (Alpha)'[:3]}\n",
    "\n",
    "    # --- ADDED CONTEXT ---\n",
    "    # 1. Volatility Context\n",
    "    # FIX: Handle cases where rolling volatility is NaN (e.g., at the start of the dataset)\n",
    "    pre_event_vol_series = full_df[full_df['Date'] < latest_row['Date']][stock_ticker].rolling(30).std()\n",
    "    pre_event_vol = pre_event_vol_series.iloc[-1] if not pre_event_vol_series.empty else np.nan\n",
    "    move_in_stdevs = abs(latest_return / pre_event_vol) if pd.notna(pre_event_vol) and pre_event_vol > 0 else 0\n",
    "\n",
    "    # 2. Historical Percentile\n",
    "    percentile = (full_df[stock_ticker] < latest_return).mean() * 100\n",
    "\n",
    "    # 3. Factor vs Alpha Breakdown\n",
    "    alpha_contrib_pct = (latest_idio / latest_return) if latest_return != 0 else 0\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are a senior quantitative analyst at a hedge fund, writing a full earnings analysis report for {stock_ticker} for a portfolio manager.\n",
    "    Your task is to synthesize the provided data into a structured report with four sections: Aggregate Analysis, Event Comparison, Deep Dive on Latest Event, and a final Conclusion.\n",
    "\n",
    "    **DATA POINTS:**\n",
    "\n",
    "    **1. Aggregate Data (from Tab 1):**\n",
    "    - Average absolute T+1 return: {avg_abs_move:.2%}\n",
    "    - Average absolute idiosyncratic (alpha) return: {avg_idio_move:.2%}\n",
    "    - Positive reaction frequency: {up_moves} out of {total_moves} events.\n",
    "\n",
    "    **2. Comparison Data (from Tab 2):**\n",
    "    - Latest Event T+1 Return: {latest_return:.2%} with {latest_idio:.2%} alpha.\n",
    "    - Previous Event T+1 Return: {f\"{second_latest_return:.2%}\" if isinstance(second_latest_return, float) else \"N/A\"} with {f\"{second_latest_alpha:.2%}\" if isinstance(second_latest_alpha, float) else \"N/A\"} alpha.\n",
    "\n",
    "    **3. Deep Dive Data on Latest Event ({latest_date}) (from Tab 3):**\n",
    "    - Statistical Significance: The {latest_return:.2%} move was a {move_in_stdevs:.1f}-sigma event, placing it in the {percentile:.1f}th percentile of historical daily returns.\n",
    "    - Attribution Breakdown: The move was composed of {latest_factor_return:.2%} from systematic factors and {latest_idio:.2%} from company-specific alpha. Alpha accounted for {alpha_contrib_pct:.1%} of the move.\n",
    "    - Key Factor Drivers:\n",
    "        - Top Positive: {', '.join([f'{k} ({v:.2%})' for k, v in list(top_3_pos.items())[:3]])}\n",
    "        - Top Negative: {', '.join([f'{k} ({v:.2%})' for k, v in list(top_3_neg.items())[:3]])}\n",
    "\n",
    "    **Your Task:**\n",
    "    Generate a report with the following markdown structure:\n",
    "    \n",
    "    ### 1. Aggregate Analysis\n",
    "    Briefly summarize the stock's typical earnings behavior using the aggregate data. Is it generally volatile? Is its movement usually company-specific?\n",
    "    \n",
    "    ### 2. Event Comparison\n",
    "    Compare the most recent earnings reaction to the one prior. Was the nature of the move (e.g., size, alpha contribution) similar or different?\n",
    "    \n",
    "    ### 3. Deep Dive on Latest Event\n",
    "    Provide a detailed analysis of the latest event. Start with its statistical significance. Then, break down the return attribution, hypothesizing the likely qualitative story for the alpha component (e.g., 'strong forward guidance' for positive alpha). Mention the key factor drivers.\n",
    "    \n",
    "    ### 4. Conclusion\n",
    "    Provide a final, concluding thought. What is the key takeaway for a portfolio manager from this entire analysis?\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = model.generate_content(prompt)\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred while generating the summary: {e}\"\n",
    "\n",
    "# --- MAIN APP ---\n",
    "def main():\n",
    "    # --- Sidebar Controls ---\n",
    "    st.sidebar.header(\"Stock Selection\")\n",
    "    stock_list = get_stock_list()\n",
    "    if not stock_list:\n",
    "        st.error(\"No stock folders found. Please create a sub-directory for each stock (e.g., 'NVDA', 'AAPL') and place the data files inside.\")\n",
    "        return\n",
    "    \n",
    "    selected_stock = st.sidebar.selectbox(\"Select Stock\", stock_list)\n",
    "    st.sidebar.markdown(\"---\")\n",
    "\n",
    "    st.title(f\"{selected_stock} Earnings Analysis Dashboard ðŸ“ˆ\")\n",
    "    st.markdown(\"### Quantitative Risk & Portfolio Construction Case Study\")\n",
    "    \n",
    "    # Load and Process\n",
    "    try:\n",
    "        returns_df, loadings_df, earnings_df = load_data(selected_stock)\n",
    "        full_df, factor_cols = process_data(returns_df, loadings_df, selected_stock)\n",
    "    except FileNotFoundError:\n",
    "        st.error(f\"Critical Error: One or more CSV files not found in the '{selected_stock}' folder. Please ensure all three required files are present.\")\n",
    "        return\n",
    "\n",
    "    st.sidebar.header(\"Configuration\")\n",
    "    window_size = st.sidebar.slider(\"Event Window (+/- Days)\", 1, 10, 5)\n",
    "    st.sidebar.markdown(\"---\")\n",
    "    api_key = st.sidebar.text_input(\"Enter Google API Key (Optional)\", type=\"password\", help=\"Required for AI Summary tab.\")\n",
    "    st.sidebar.markdown(\"---\")\n",
    "    st.sidebar.header(f\"{selected_stock} Event Deep Dive\")\n",
    "    \n",
    "    # Select Event Logic\n",
    "    default_index = len(earnings_df) - 1 if len(earnings_df) > 0 else 0\n",
    "    selected_date = st.sidebar.selectbox(\"Select Earnings Date\", earnings_df['Earnings Date'].dt.strftime('%Y-%m-%d'), index=default_index)\n",
    "    selected_date_dt = pd.to_datetime(selected_date)\n",
    "    \n",
    "    # --- Main Page Layout (Tabs) ---\n",
    "    tab1, tab2, tab3, tab4, tab5 = st.tabs([\"ðŸ“Š Aggregate Analysis\", \"âš–ï¸ Event Comparison\", \"ðŸ” Individual Deep Dive\", \"ðŸ¤– AI Summary\", \"ðŸ“ˆ Factor Performance\"])\n",
    "\n",
    "    # --- Tab 1: Aggregate Statistics ---\n",
    "    with tab1:\n",
    "        st.header(f\"Aggregate Earnings Impact for {selected_stock}\")\n",
    "        \n",
    "        all_events = []\n",
    "        for date in earnings_df['Earnings Date']:\n",
    "            w_df = get_event_window(full_df, date, window_size)\n",
    "            if w_df is not None:\n",
    "                w_df['Event_ID'] = date.strftime('%Y-%m-%d')\n",
    "                all_events.append(w_df)\n",
    "        \n",
    "        if all_events:\n",
    "            combined_events = pd.concat(all_events)\n",
    "            reaction_days = combined_events[combined_events['Rel_Day'] == 1]\n",
    "            \n",
    "            col1, col2, col3, col4 = st.columns(4)\n",
    "            with col1:\n",
    "                st.metric(\"**Avg Abs Move (T+1)**\", f\"{reaction_days[selected_stock].abs().mean():.2%}\")\n",
    "            with col2:\n",
    "                st.metric(\"**Avg Idiosyncratic Move**\", f\"{reaction_days['Idiosyncratic_Return'].abs().mean():.2%}\")\n",
    "            with col3:\n",
    "                corr_t1 = reaction_days[selected_stock].corr(reaction_days['Idiosyncratic_Return'])\n",
    "                st.metric(\"**Total/Idio Correlation**\", f\"{corr_t1:.2f}\")\n",
    "            with col4:\n",
    "                up_moves = (reaction_days[selected_stock] > 0).sum()\n",
    "                st.metric(\"**Positive Reactions**\", f\"{up_moves}/{len(reaction_days)}\")\n",
    "\n",
    "            avg_cum_ret = combined_events.groupby('Rel_Day')[[selected_stock, 'Factor_Return', 'Idiosyncratic_Return']].mean().cumsum()\n",
    "            \n",
    "            fig_agg = px.line(avg_cum_ret, x=avg_cum_ret.index, y=[selected_stock, 'Factor_Return', 'Idiosyncratic_Return'],\n",
    "                              title=f\"Average Cumulative Returns (T-{window_size} to T+{window_size})\",\n",
    "                              labels={'value': 'Cumulative Return', 'Rel_Day': 'Days Relative to Earnings'})\n",
    "            \n",
    "            fig_agg.add_vline(x=0, line_dash=\"dash\", line_color=\"white\", annotation_text=\"Announcement\")\n",
    "            st.plotly_chart(fig_agg, use_container_width=True)\n",
    "\n",
    "            st.markdown(\"---\")\n",
    "            \n",
    "            # --- ADDED: Distribution and Top Movers ---\n",
    "            col_dist, col_movers = st.columns(2)\n",
    "\n",
    "            with col_dist:\n",
    "                st.subheader(\"Distribution of T+1 Reactions\")\n",
    "                fig_box = px.box(reaction_days, y=selected_stock, points=\"all\",\n",
    "                                 title=f\"Distribution of All T+1 Returns for {selected_stock}\",\n",
    "                                 labels={selected_stock: \"T+1 Daily Return\"})\n",
    "                fig_box.update_layout(yaxis_tickformat=\".1%\")\n",
    "                st.plotly_chart(fig_box, use_container_width=True)\n",
    "\n",
    "            with col_movers:\n",
    "                st.subheader(\"Most Significant Reactions\")\n",
    "                sorted_reactions = reaction_days.sort_values(by=selected_stock, ascending=False)\n",
    "                top_3 = sorted_reactions[['Event_ID', selected_stock]].head(3)\n",
    "                bottom_3 = sorted_reactions[['Event_ID', selected_stock]].tail(3).sort_values(by=selected_stock)\n",
    "\n",
    "                st.markdown(\"**Top 3 Positive Reactions**\")\n",
    "                st.dataframe(top_3, use_container_width=True, hide_index=True, column_config={selected_stock: st.column_config.NumberColumn(format=\"%.2f%%\")})\n",
    "                st.markdown(\"**Top 3 Negative Reactions**\")\n",
    "                st.dataframe(bottom_3, use_container_width=True, hide_index=True, column_config={selected_stock: st.column_config.NumberColumn(format=\"%.2f%%\")})\n",
    "\n",
    "    # --- Tab 2: Comparison ---\n",
    "    with tab2:\n",
    "        st.header(f\"Compare Two {selected_stock} Earnings Events\")\n",
    "        comp_col1, comp_col2 = st.columns(2)\n",
    "        \n",
    "        default_idx_a = len(earnings_df)-1 if len(earnings_df) >= 1 else 0\n",
    "        default_idx_b = len(earnings_df)-2 if len(earnings_df) >= 2 else 0\n",
    "\n",
    "        with comp_col1:\n",
    "            date_a_str = st.selectbox(\"Event A\", earnings_df['Earnings Date'].dt.strftime('%Y-%m-%d'), index=default_idx_a, key=\"comp_a\")\n",
    "            date_a = pd.to_datetime(date_a_str)\n",
    "            t1_a = full_df[full_df['Date'] == date_a + pd.Timedelta(days=1)]\n",
    "            if not t1_a.empty:\n",
    "                st.plotly_chart(create_waterfall(t1_a.iloc[0], factor_cols, f\"Attribution: {date_a_str}\"), use_container_width=True)\n",
    "\n",
    "        with comp_col2:\n",
    "            date_b_str = st.selectbox(\"Event B\", earnings_df['Earnings Date'].dt.strftime('%Y-%m-%d'), index=default_idx_b, key=\"comp_b\")\n",
    "            date_b = pd.to_datetime(date_b_str)\n",
    "            t1_b = full_df[full_df['Date'] == date_b + pd.Timedelta(days=1)]\n",
    "            if not t1_b.empty:\n",
    "                st.plotly_chart(create_waterfall(t1_b.iloc[0], factor_cols, f\"Attribution: {date_b_str}\"), use_container_width=True)\n",
    "\n",
    "    # --- Tab 3: Individual Deep Dive (Enhanced) ---\n",
    "    with tab3:\n",
    "        st.header(f\"Individual Deep Dive: {selected_stock} - {selected_date}\")\n",
    "        event_window = get_event_window(full_df, selected_date_dt, window_size)\n",
    "        \n",
    "        if event_window is not None:\n",
    "            t_plus_1 = event_window[event_window['Rel_Day'] == 1]\n",
    "            \n",
    "            if not t_plus_1.empty:\n",
    "                row = t_plus_1.iloc[0]\n",
    "                \n",
    "                # 1. Return Attribution Waterfall\n",
    "                st.subheader(f\"1. Return Attribution (T+1)\")\n",
    "                st.plotly_chart(create_waterfall(row, factor_cols, \"\"), use_container_width=True)\n",
    "\n",
    "                # 2. Top Contributors Text\n",
    "                all_contribs = {col: row[f'Contrib_{col}'] for col in factor_cols}\n",
    "                all_contribs['Idiosyncratic'] = row['Idiosyncratic_Return']\n",
    "                sorted_contribs = sorted(all_contribs.items(), key=lambda x: x[1], reverse=True)\n",
    "                \n",
    "                col_d1, col_d2 = st.columns(2)\n",
    "                with col_d1:\n",
    "                    st.markdown(\"**Top Positive Drivers:**\")\n",
    "                    for k, v in [i for i in sorted_contribs if i[1] > 0][:3]:\n",
    "                        st.write(f\"- {k}: `{v:.2%}`\")\n",
    "                with col_d2:\n",
    "                    st.markdown(\"**Top Negative Drivers:**\")\n",
    "                    for k, v in [i for i in reversed(sorted_contribs) if i[1] < 0][:3]:\n",
    "                        st.write(f\"- {k}: `{v:.2%}`\")\n",
    "\n",
    "                st.markdown(\"---\")\n",
    "\n",
    "                # 3. Historical Context Histogram (New Feature)\n",
    "                st.subheader(\"2. Historical Context\")\n",
    "                col_h1, col_h2 = st.columns([2, 1])\n",
    "                \n",
    "                with col_h1:\n",
    "                    fig_hist = px.histogram(full_df, x=selected_stock, nbins=100, title=\"Distribution of All Historical Daily Returns\",\n",
    "                                            labels={selected_stock: 'Daily Return'})\n",
    "                    fig_hist.add_vline(x=row[selected_stock], line_dash=\"dash\", line_color=\"red\", \n",
    "                                       annotation_text=f\"Event: {row[selected_stock]:.2%}\")\n",
    "                    st.plotly_chart(fig_hist, use_container_width=True)\n",
    "                \n",
    "                with col_h2:\n",
    "                    percentile = (full_df[selected_stock] < row[selected_stock]).mean() * 100\n",
    "                    st.info(f\"The T+1 return of **{row[selected_stock]:.2%}** is in the **{percentile:.1f}th percentile** of all daily returns since Sept 2022.\")\n",
    "\n",
    "                st.markdown(\"---\")\n",
    "\n",
    "                # 4. Factor Exposure Evolution (New Feature)\n",
    "                st.subheader(\"3. Factor Beta Evolution (Risk Exposure)\")\n",
    "                top_factors = [x[0] for x in sorted(all_contribs.items(), key=lambda x: abs(x[1]), reverse=True) if x[0] != 'Idiosyncratic'][:5]\n",
    "                selected_factors = st.multiselect(\"Select Factors to View Betas:\", factor_cols, default=top_factors)\n",
    "                \n",
    "                if selected_factors:\n",
    "                    loading_cols = [f\"{f}_Load\" for f in selected_factors]\n",
    "                    fig_load = px.line(event_window, x='Rel_Day', y=loading_cols, \n",
    "                                       title=\"Factor Loadings (Betas) During Event Window\",\n",
    "                                       labels={'value': 'Beta', 'Rel_Day': 'Days Relative to Earnings'})\n",
    "                    fig_load.add_vline(x=0, line_dash=\"dash\", line_color=\"white\", annotation_text=\"Announcement\")\n",
    "                    st.plotly_chart(fig_load, use_container_width=True)\n",
    "\n",
    "                st.markdown(\"---\")\n",
    "\n",
    "                # 5. Volatility Context (Enhanced)\n",
    "                st.subheader(\"4. Volatility Context\")\n",
    "                \n",
    "                # Calculate Rolling Volatility (Annualized)\n",
    "                trading_days = 252\n",
    "                full_df['Rolling_Vol'] = full_df[selected_stock].rolling(30).std() * np.sqrt(trading_days)\n",
    "                \n",
    "                # Get pre-event vol (last available day before window)\n",
    "                pre_event_data = full_df[full_df['Date'] < event_window['Date'].min()]\n",
    "                prior_vol = pre_event_data['Rolling_Vol'].iloc[-1] if not pre_event_data.empty else np.nan\n",
    "                \n",
    "                col_v1, col_v2 = st.columns(2)\n",
    "                col_v1.metric(\"Pre-Event 30-Day Volatility (Annualized)\", f\"{prior_vol:.1%}\" if pd.notna(prior_vol) else \"N/A\")\n",
    "                col_v2.caption(\"Comparing the implied stability before the event to the actual realization.\")\n",
    "\n",
    "                with st.expander(\"View Raw Event Data\"):\n",
    "                    st.dataframe(event_window)\n",
    "\n",
    "    # --- Tab 4: AI Summary ---\n",
    "    with tab4:\n",
    "        st.header(f\"AI-Generated Analyst Summary for {selected_stock}\")\n",
    "\n",
    "        # Use session state to hold the summary\n",
    "        if 'ai_summary' not in st.session_state:\n",
    "            st.session_state.ai_summary = None\n",
    "        if 'summary_stock' not in st.session_state:\n",
    "            st.session_state.summary_stock = None\n",
    "\n",
    "        if st.button(\"Generate Report\"):\n",
    "            if not api_key:\n",
    "                st.warning(\"Please enter an API Key in the sidebar.\")\n",
    "                st.session_state.ai_summary = None # Clear previous summary\n",
    "            else:\n",
    "                # Prepare data\n",
    "                reaction_days = combined_events[combined_events['Rel_Day'] == 1]\n",
    "                \n",
    "                # Get latest and second latest event data\n",
    "                latest_event_date = earnings_df['Earnings Date'].max()\n",
    "                latest_reaction = full_df[full_df['Date'] == latest_event_date + pd.Timedelta(days=1)]\n",
    "                \n",
    "                second_latest_event_date = earnings_df['Earnings Date'].nlargest(2).iloc[-1] if len(earnings_df) > 1 else None\n",
    "                second_latest_reaction = full_df[full_df['Date'] == second_latest_event_date + pd.Timedelta(days=1)] if second_latest_event_date else pd.DataFrame()\n",
    "                \n",
    "                if not latest_reaction.empty:\n",
    "                    with st.spinner(\"Analyzing...\"):\n",
    "                        st.session_state.ai_summary = generate_ai_summary(api_key, selected_stock, full_df, reaction_days, latest_reaction, second_latest_reaction, factor_cols)\n",
    "                        st.session_state.summary_stock = selected_stock # Store which stock this summary is for\n",
    "                else:\n",
    "                    st.error(\"No data available for the most recent earnings date.\")\n",
    "                    st.session_state.ai_summary = None\n",
    "\n",
    "        # Display the summary and download button if it exists for the current stock\n",
    "        if st.session_state.ai_summary and st.session_state.summary_stock == selected_stock:\n",
    "            st.markdown(\"---\")\n",
    "            st.markdown(st.session_state.ai_summary)\n",
    "            st.download_button(\n",
    "                label=\"ðŸ“¥ Download Summary\",\n",
    "                data=st.session_state.ai_summary,\n",
    "                file_name=f\"AI_Summary_{selected_stock}_{pd.Timestamp.now().strftime('%Y%m%d')}.txt\",\n",
    "                mime=\"text/plain\",\n",
    "            )\n",
    "\n",
    "    # --- Tab 5: Factor Performance ---\n",
    "    with tab5:\n",
    "        st.header(\"Historical Risk Factor Performance\")\n",
    "        st.markdown(\"Analyze the cumulative performance of the underlying risk factors over the entire historical period.\")\n",
    "\n",
    "        # The factor columns are available in `factor_cols`\n",
    "        default_factors = ['Market', 'Semiconductors', 'Value']\n",
    "        # Ensure default factors exist in the available columns\n",
    "        default_factors = [f for f in default_factors if f in factor_cols]\n",
    "\n",
    "        selected_factors_perf = st.multiselect(\"Select factors to plot:\", factor_cols, default=default_factors, key=\"factor_perf_select\")\n",
    "\n",
    "        if selected_factors_perf:\n",
    "            # Calculate cumulative returns for selected factors from the original returns_df\n",
    "            factor_perf_df = returns_df[['Date'] + selected_factors_perf].copy()\n",
    "            factor_perf_df[selected_factors_perf] = factor_perf_df[selected_factors_perf].cumsum()\n",
    "\n",
    "            fig_factor_perf = px.line(factor_perf_df, x='Date', y=selected_factors_perf, title=\"Cumulative Factor Returns\")\n",
    "            st.plotly_chart(fig_factor_perf, use_container_width=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680aebdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "from scipy.stats.mstats import winsorize\n",
    "from arch import arch_model\n",
    "\n",
    "# --- Page Config ---\n",
    "st.set_page_config(layout=\"wide\", page_title=\"KR Capital: Earnings Dashboard\")\n",
    "\n",
    "# --- Dynamic Stock Folder Logic ---\n",
    "def get_stock_list(path='res'):\n",
    "    \"\"\"Scans for subdirectories which are assumed to be stock tickers.\"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "        return []\n",
    "    return [d for d in os.listdir(path) if os.path.isdir(os.path.join(path, d)) and not d.startswith('.')]\n",
    "\n",
    "# --- Data Loading Functions ---\n",
    "@st.cache_data\n",
    "def load_data(stock_folder):\n",
    "    \"\"\"Loads data for a specific stock from its folder.\"\"\"\n",
    "    base_path = os.path.join('res', stock_folder)\n",
    "\n",
    "    # Helper to robustly load CSVs\n",
    "    def robust_read(filename):\n",
    "        file_path = os.path.join(base_path, filename)\n",
    "        if not os.path.exists(file_path):\n",
    "            raise FileNotFoundError(f\"{filename}\")\n",
    "        try:\n",
    "            # Try skipping header info (common in financial exports)\n",
    "            return pd.read_csv(file_path, skiprows=2)\n",
    "        except:\n",
    "            # Fallback to standard read\n",
    "            return pd.read_csv(file_path)\n",
    "\n",
    "    # Load Returns\n",
    "    returns_df = robust_read(\"01_case_study_returns.csv\")\n",
    "    returns_df['Date'] = pd.to_datetime(returns_df['Date'], format='%m/%d/%y', errors='coerce')\n",
    "    returns_df = returns_df.dropna(subset=['Date'])\n",
    "    \n",
    "    # Load Loadings\n",
    "    loadings_df = robust_read(\"02_case_study_factor_loadings.csv\")\n",
    "    loadings_df['Date'] = pd.to_datetime(loadings_df['Date'], format='mixed', errors='coerce')\n",
    "    loadings_df = loadings_df.dropna(subset=['Date'])\n",
    "\n",
    "    # Load Earnings Dates\n",
    "    earnings_df = robust_read(\"03_case_study_earnings_dates.csv\")\n",
    "    # Extract the first column regardless of name and clean it\n",
    "    earnings_df = earnings_df.iloc[:, 0].to_frame(name='Earnings Date')\n",
    "    earnings_df['Earnings Date'] = pd.to_datetime(earnings_df['Earnings Date'], errors='coerce')\n",
    "    earnings_df = earnings_df.dropna()\n",
    "    \n",
    "    return returns_df, loadings_df, earnings_df\n",
    "\n",
    "# --- Data Processing ---\n",
    "def process_data(returns_df, loadings_df, stock_ticker):\n",
    "    # Ensure column names are clean\n",
    "    returns_df.columns = returns_df.columns.str.strip()\n",
    "    loadings_df.columns = loadings_df.columns.str.strip()\n",
    "\n",
    "    # Merge Returns and Loadings\n",
    "    df = pd.merge(returns_df, loadings_df, on='Date', suffixes=('_Ret', '_Load'))\n",
    "    \n",
    "    # Identify Factor Columns\n",
    "    base_cols = [c.replace('_Ret', '') for c in df.columns if '_Ret' in c and stock_ticker not in c and 'Date' not in c]\n",
    "    \n",
    "    # Calculate Factor Contribution\n",
    "    df['Factor_Return'] = 0.0\n",
    "    for col in base_cols:\n",
    "        ret_col = f\"{col}_Ret\"\n",
    "        load_col = f\"{col}_Load\"\n",
    "        if ret_col in df.columns and load_col in df.columns:\n",
    "            df[f'Contrib_{col}'] = df[ret_col] * df[load_col]\n",
    "            df['Factor_Return'] += df[f'Contrib_{col}']\n",
    "            \n",
    "    # Calculate Idiosyncratic Return (Alpha)\n",
    "    df['Idiosyncratic_Return'] = df[stock_ticker] - df['Factor_Return']\n",
    "    \n",
    "    return df, base_cols\n",
    "\n",
    "# --- Event Study Logic ---\n",
    "def get_event_window(df, earnings_date, window_days=5):\n",
    "    try:\n",
    "        df = df.sort_values('Date').reset_index(drop=True)\n",
    "        idx_list = df.index[df['Date'] == earnings_date].tolist()\n",
    "        \n",
    "        if not idx_list:\n",
    "            return None\n",
    "            \n",
    "        t0_idx = idx_list[0]\n",
    "        \n",
    "        # Check bounds\n",
    "        start_idx = max(0, t0_idx - window_days)\n",
    "        end_idx = min(len(df) - 1, t0_idx + window_days + 1)\n",
    "        \n",
    "        window_df = df.iloc[start_idx:end_idx].copy()\n",
    "        window_df['Rel_Day'] = window_df.index - t0_idx\n",
    "        \n",
    "        return window_df\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "# --- Plotly Waterfall Chart Function ---\n",
    "def create_waterfall(row, factor_cols, title):\n",
    "    factors = {col: row[f'Contrib_{col}'] for col in factor_cols}\n",
    "    sorted_factors = dict(sorted(factors.items(), key=lambda item: abs(item[1]), reverse=True))\n",
    "    \n",
    "    top_n = 5\n",
    "    wf_labels = ['Idiosyncratic (Alpha)'] + list(sorted_factors.keys())[:top_n] + ['Other Factors']\n",
    "    wf_values = [row['Idiosyncratic_Return']] + list(sorted_factors.values())[:top_n]\n",
    "    \n",
    "    other_sum = sum(list(sorted_factors.values())[top_n:])\n",
    "    wf_values.append(other_sum)\n",
    "\n",
    "    fig = go.Figure(go.Waterfall(\n",
    "        name = \"Return Attribution\", orientation = \"v\",\n",
    "        measure = [\"relative\"] * len(wf_values) + [\"total\"],\n",
    "        x = wf_labels + [\"Total Return\"],\n",
    "        textposition = \"outside\",\n",
    "        textfont_size=10, \n",
    "        text = [f\"{v:.1%}\" for v in wf_values + [sum(wf_values)]],\n",
    "        y = wf_values + [0],\n",
    "        connector = {\"line\":{\"color\":\"rgb(63, 63, 63)\"}},\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title = title,\n",
    "        showlegend = False,\n",
    "        yaxis_tickformat = '.1%',\n",
    "        height=500\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "# --- GARCH Volatility Forecast Function ---\n",
    "@st.cache_data\n",
    "def get_garch_forecast(returns_series):\n",
    "    \"\"\"\n",
    "    Fits a GARCH(1,1) model and returns the one-step-ahead daily volatility forecast.\n",
    "    Returns forecast and a status message.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # GARCH models often converge better when returns are scaled (e.g., by 100)\n",
    "        garch_model = arch_model(returns_series * 100, vol='Garch', p=1, q=1, dist='Normal')\n",
    "        res = garch_model.fit(disp='off') # disp='off' suppresses convergence output\n",
    "        \n",
    "        # Forecast one step ahead\n",
    "        forecast = res.forecast(horizon=1)\n",
    "        \n",
    "        # The output is variance, so we need the square root for volatility. Also scale back from %.\n",
    "        predicted_vol = np.sqrt(forecast.variance.iloc[-1, 0]) / 100\n",
    "        \n",
    "        return predicted_vol, \"GARCH(1,1) Forecast\"\n",
    "    except Exception as e:\n",
    "        # Fallback to simple 30-day rolling standard deviation if GARCH fails\n",
    "        fallback_vol = returns_series.rolling(30).std().iloc[-1]\n",
    "        return fallback_vol, \"GARCH Failed, Fallback to 30D StdDev\"\n",
    "\n",
    "def generate_ai_summary(api_key, stock_ticker, full_df, reaction_days, latest_reaction, second_latest_reaction, factor_cols, combined_events):\n",
    "    try:\n",
    "        genai.configure(api_key=api_key)\n",
    "        model = genai.GenerativeModel('gemini-pro-latest')\n",
    "    except Exception as e:\n",
    "        return f\"Error configuring AI model: {e}\"\n",
    "\n",
    "    # --- 1. Aggregate Metrics ---\n",
    "    avg_abs_move = reaction_days[stock_ticker].abs().mean()\n",
    "    avg_idio_move = reaction_days['Idiosyncratic_Return'].abs().mean()\n",
    "    avg_alpha_contrib = (reaction_days['Idiosyncratic_Return'].abs() / reaction_days[stock_ticker].abs()).mean()\n",
    "    up_moves = (reaction_days[stock_ticker] > 0).sum()\n",
    "    total_moves = len(reaction_days)\n",
    "\n",
    "    \n",
    "    # Calculate average absolute move per quarter to identify seasonal volatility\n",
    "    seasonality = reaction_days.groupby('Quarter')[stock_ticker].apply(lambda x: x.abs().mean()).to_dict()\n",
    "    seasonality_str = \", \".join([f\"Q{int(k)}: {v:.1%}\" for k, v in seasonality.items()])\n",
    "\n",
    "    # --- 2. Behavior Metrics (Drift) ---\n",
    "    drift_correlations = []\n",
    "    for event_id in reaction_days['Event_ID'].unique():\n",
    "        event_window = combined_events[combined_events['Event_ID'] == event_id]\n",
    "        if len(event_window) >= 5:\n",
    "            t1_move = event_window[event_window['Rel_Day'] == 1][stock_ticker].values\n",
    "            drift_move = event_window[(event_window['Rel_Day'] > 1) & (event_window['Rel_Day'] <= 5)][stock_ticker].sum()\n",
    "            if len(t1_move) > 0:\n",
    "                drift_correlations.append({'t1': t1_move[0], 'drift': drift_move})\n",
    "    \n",
    "    drift_df = pd.DataFrame(drift_correlations)\n",
    "    drift_corr = drift_df['t1'].corr(drift_df['drift']) if not drift_df.empty else 0\n",
    "    behavior_desc = \"Momentum (Continuation)\" if drift_corr > 0.15 else \"Mean Reversion (Reversal)\" if drift_corr < -0.15 else \"Random Walk (No pattern)\"\n",
    "\n",
    "    # --- 3. Latest Event Data ---\n",
    "    row = latest_reaction.iloc[0]\n",
    "    latest_date = row['Date'].strftime('%Y-%m-%d')\n",
    "    latest_ret = row[stock_ticker]\n",
    "    latest_idio = row['Idiosyncratic_Return']\n",
    "    \n",
    "    # Volatility Context (Sigma)\n",
    "    pre_event_vol_series = full_df[full_df['Date'] < row['Date']][stock_ticker].rolling(30).std()\n",
    "    pre_event_vol = pre_event_vol_series.iloc[-1] if not pre_event_vol_series.empty else 0.02\n",
    "    sigma_move = abs(latest_ret / pre_event_vol) if pre_event_vol > 0 else 0\n",
    "    \n",
    "    \n",
    "    percentile = (full_df[stock_ticker] < latest_ret).mean() * 100\n",
    "\n",
    "    # Comparison Data\n",
    "    prev_ret = second_latest_reaction.iloc[0][stock_ticker] if not second_latest_reaction.empty else 0\n",
    "    \n",
    "    # Top Factors\n",
    "    factors = {col: row[f'Contrib_{col}'] for col in factor_cols}\n",
    "    sorted_factors = sorted(factors.items(), key=lambda item: item[1], reverse=True)\n",
    "    top_pos = [f\"{k} ({v:.1%})\" for k, v in sorted_factors if v > 0][:3]\n",
    "    top_neg = [f\"{k} ({v:.1%})\" for k, v in sorted_factors if v < 0][-3:]\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are a fundamental Portfolio Manager at a quantitative hedge fund. Write a strategic post-earnings analysis for {stock_ticker}.\n",
    "    \n",
    "    **1. AGGREGATE PROFILE:**\n",
    "    - Avg Earnings Move: {avg_abs_move:.1%} (of which {avg_alpha_contrib:.0%} is usually Idiosyncratic Alpha).\n",
    "    - Seasonality (Avg Move by Quarter): {seasonality_str}. (Note any quarters that are typically more volatile).\n",
    "    - Win Rate: {up_moves}/{total_moves} positive reactions.\n",
    "    - Post-Earnings Drift Correlation: {drift_corr:.2f} ({behavior_desc}).\n",
    "\n",
    "    **2. LATEST EVENT ({latest_date}):**\n",
    "    - Move: {latest_ret:.1%} ({sigma_move:.1f}x Sigma vs 30-day baseline).\n",
    "    - Historical Context: This return is in the {percentile:.1f}th percentile of all daily moves.\n",
    "    - Alpha: {latest_idio:.1%}.\n",
    "    - Top Drivers: Positive [{', '.join(top_pos)}], Negative [{', '.join(top_neg)}].\n",
    "    - Comparison to Previous Q: Previous move was {prev_ret:.1%}.\n",
    "\n",
    "    **OUTPUT FORMAT (Markdown):**\n",
    "    \n",
    "    ### 1. Executive Summary\n",
    "    One sentence characterizing the event (e.g., \"A volatility shock driven by pure alpha\" or \"A non-event dampening volatility\").\n",
    "\n",
    "    ### 2. Return Attribution & Seasonality\n",
    "    Analyze the latest move vs the previous quarter. Was it sector-driven or company-specific? Does this align with the typical seasonality for this quarter ({seasonality_str})?\n",
    "\n",
    "    ### 3. Volatility & Behavioral Analysis\n",
    "    Discuss the risk. Is the {sigma_move:.1f}-Sigma move abnormal? Note the percentile ranking. Based on the Drift Correlation ({drift_corr:.2f}), what is the trading bias for the next week?\n",
    "\n",
    "    ### 4. Conclusion\n",
    "    Synthesize the \"Earnings Personality\" of {stock_ticker}. Is it a reliable trend-follower post-earnings, or a mean-reverting volatility trap?\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = model.generate_content(prompt)\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        return f\"AI Generation Error: {e}\"\n",
    "# --- MAIN APP ---\n",
    "def main():\n",
    "    # --- Sidebar Controls ---\n",
    "    st.sidebar.header(\"Stock Selection\")\n",
    "    stock_list = get_stock_list()\n",
    "    \n",
    "    if not stock_list:\n",
    "        st.error(\"âš ï¸ No stock folders found in 'res/'. Please create a subdirectory for each stock (e.g., 'res/NVDA') containing the 3 required CSV files.\")\n",
    "        st.stop()\n",
    "    \n",
    "    selected_stock = st.sidebar.selectbox(\"Select Stock\", stock_list)\n",
    "    st.sidebar.markdown(\"---\")\n",
    "\n",
    "    st.title(f\"{selected_stock} Earnings Analysis Dashboard ðŸ“ˆ\")\n",
    "    st.markdown(\"### Quantitative Risk & Portfolio Construction Case Study\")\n",
    "    \n",
    "    # Load and Process\n",
    "    try:\n",
    "        returns_df, loadings_df, earnings_df = load_data(selected_stock)\n",
    "        full_df, factor_cols = process_data(returns_df, loadings_df, selected_stock)\n",
    "    except FileNotFoundError as e:\n",
    "        st.error(f\"Critical Error: Missing file {e} in the '{selected_stock}' folder.\")\n",
    "        st.stop()\n",
    "    except Exception as e:\n",
    "        st.error(f\"Error loading data: {e}\")\n",
    "        st.stop()\n",
    "\n",
    "    # --- DATA HEALTH CHECK ---\n",
    "    with st.expander(\"Data Health Check\"):\n",
    "        col_h1, col_h2, col_h3 = st.columns(3)\n",
    "        with col_h1:\n",
    "            st.metric(\"Date Range\", f\"{full_df['Date'].min().strftime('%Y-%m-%d')} to {full_df['Date'].max().strftime('%Y-%m-%d')}\")\n",
    "        \n",
    "        missing_vals = full_df.isnull().sum().sum()\n",
    "        with col_h2:\n",
    "            st.metric(\"Missing Values Found\", f\"{missing_vals}\")\n",
    "        \n",
    "        duplicate_dates = full_df['Date'].duplicated().sum()\n",
    "        with col_h3:\n",
    "            st.metric(\"Duplicate Dates Found\", f\"{duplicate_dates}\")\n",
    "\n",
    "        if missing_vals > 0:\n",
    "            st.warning(\"Missing values were found and have been forward-filled. This assumes that on a non-trading day, the last known value is carried forward.\")\n",
    "            # Simple forward-fill for all columns\n",
    "            full_df = full_df.fillna(method='ffill').dropna() # drop any remaining NaNs at the start\n",
    "        \n",
    "        if duplicate_dates > 0:\n",
    "            st.error(\"Duplicate dates were found and removed. Please check the source data integrity.\")\n",
    "            full_df = full_df.drop_duplicates(subset=['Date'], keep='first')\n",
    "\n",
    "    st.sidebar.header(\"Configuration\")\n",
    "    window_size = st.sidebar.slider(\"Event Window (+/- Days)\", 1, 10, 5)\n",
    "    st.sidebar.markdown(\"---\")\n",
    "    api_key = st.sidebar.text_input(\"Enter Google API Key (Optional)\", type=\"password\", help=\"Required for AI Summary tab.\")\n",
    "    st.sidebar.markdown(\"---\")\n",
    "    st.sidebar.header(f\"{selected_stock} Event Deep Dive\")\n",
    "    \n",
    "    # --- ADDED: Winsorization Control ---\n",
    "    st.sidebar.markdown(\"---\")\n",
    "    st.sidebar.header(\"Advanced Settings\")\n",
    "    winsorize_level = st.sidebar.slider(\"Winsorize Returns Level (%)\", 0, 5, 0, help=\"Set extreme outliers to a specified percentile. 0% means no winsorization.\")\n",
    "    if winsorize_level > 0:\n",
    "        limit = winsorize_level / 100.0\n",
    "        # Apply winsorization to all return columns in the dataframe\n",
    "        return_cols = [col for col in returns_df.columns if col != 'Date']\n",
    "        for col in return_cols:\n",
    "            returns_df[col] = winsorize(returns_df[col], limits=[limit, limit])\n",
    "        st.sidebar.info(f\"Returns are being winsorized at the {winsorize_level}th percentile.\")\n",
    "    \n",
    "    z_score_view = st.sidebar.checkbox(\"Enable Z-Score View in Factor Tab\")\n",
    "\n",
    "\n",
    "    # Select Event Logic\n",
    "    default_index = len(earnings_df) - 1 if len(earnings_df) > 0 else 0\n",
    "    selected_date = st.sidebar.selectbox(\"Select Earnings Date\", earnings_df['Earnings Date'].dt.strftime('%Y-%m-%d'), index=default_index)\n",
    "    selected_date_dt = pd.to_datetime(selected_date)\n",
    "    \n",
    "    # --- Main Page Layout (Tabs) ---\n",
    "    tab1, tab2, tab3, tab4, tab5 = st.tabs([\"ðŸ“Š Aggregate Analysis\", \"âš–ï¸ Event Comparison\", \"ðŸ” Individual Deep Dive\", \"ðŸ¤– AI Summary\", \"ðŸ“ˆ Factor Performance\"])\n",
    "\n",
    "    # --- Tab 1: Aggregate Statistics ---\n",
    "    with tab1:\n",
    "        st.header(f\"Aggregate Earnings Impact for {selected_stock}\")\n",
    "        \n",
    "        all_events = []\n",
    "        for date in earnings_df['Earnings Date']:\n",
    "            w_df = get_event_window(full_df, date, window_size)\n",
    "            if w_df is not None:\n",
    "                w_df['Event_ID'] = date.strftime('%Y-%m-%d')\n",
    "                w_df['Quarter'] = date.quarter # Add quarter info\n",
    "                all_events.append(w_df)\n",
    "        \n",
    "        if all_events:\n",
    "            combined_events = pd.concat(all_events)\n",
    "            reaction_days = combined_events[combined_events['Rel_Day'] == 1]\n",
    "            \n",
    "            col1, col2, col3, col4 = st.columns(4)\n",
    "            with col1:\n",
    "                st.metric(\"**Avg Abs Move (T+1)**\", f\"{reaction_days[selected_stock].abs().mean():.2%}\")\n",
    "            with col2:\n",
    "                st.metric(\"**Avg Idiosyncratic Move**\", f\"{reaction_days['Idiosyncratic_Return'].abs().mean():.2%}\")\n",
    "            with col3:\n",
    "                corr_t1 = reaction_days[selected_stock].corr(reaction_days['Idiosyncratic_Return'])\n",
    "                st.metric(\"**Total/Idio Correlation**\", f\"{corr_t1:.2f}\")\n",
    "            with col4:\n",
    "                up_moves = (reaction_days[selected_stock] > 0).sum()\n",
    "                st.metric(\"**Positive Reactions**\", f\"{up_moves}/{len(reaction_days)}\")\n",
    "\n",
    "            # Cumulative Return Chart\n",
    "            avg_cum_ret = combined_events.groupby('Rel_Day')[[selected_stock, 'Factor_Return', 'Idiosyncratic_Return']].mean().cumsum()\n",
    "            \n",
    "            fig_agg = px.line(avg_cum_ret, x=avg_cum_ret.index, y=[selected_stock, 'Factor_Return', 'Idiosyncratic_Return'],\n",
    "                              title=f\"Average Cumulative Returns (T-{window_size} to T+{window_size})\",\n",
    "                              labels={'value': 'Cumulative Return', 'Rel_Day': 'Days Relative to Earnings'})\n",
    "            \n",
    "            fig_agg.add_vline(x=0, line_dash=\"dash\", line_color=\"white\", annotation_text=\"Announcement\")\n",
    "            st.plotly_chart(fig_agg, use_container_width=True)\n",
    "\n",
    "            st.markdown(\"---\")\n",
    "            \n",
    "            # --- NEW SECTION: Advanced Analytics ---\n",
    "            st.subheader(\"Advanced Analytics\")\n",
    "            col_adv1, col_adv2 = st.columns(2)\n",
    "\n",
    "            with col_adv1:\n",
    "                # 1. Seasonality Analysis\n",
    "                st.markdown(\"**Seasonality: Avg Absolute Move by Quarter**\")\n",
    "                quarterly_stats = reaction_days.groupby('Quarter')[selected_stock].apply(lambda x: x.abs().mean()).reset_index()\n",
    "                quarterly_stats['Quarter'] = 'Q' + quarterly_stats['Quarter'].astype(str)\n",
    "                fig_season = px.bar(quarterly_stats, x='Quarter', y=selected_stock, \n",
    "                                    labels={selected_stock: \"Avg Abs Return\"},\n",
    "                                    color=selected_stock, color_continuous_scale=\"Blues\")\n",
    "                fig_season.update_layout(yaxis_tickformat=\".2%\")\n",
    "                st.plotly_chart(fig_season, use_container_width=True)\n",
    "\n",
    "            with col_adv2:\n",
    "                # 2. Alpha vs Total Correlation Plot\n",
    "                st.markdown(\"**Correlation: Total Return vs. Alpha (T+1)**\")\n",
    "                fig_corr = px.scatter(reaction_days, x=selected_stock, y='Idiosyncratic_Return',\n",
    "                                      hover_data=['Event_ID'],\n",
    "                                      labels={selected_stock: 'Total T+1 Return', 'Idiosyncratic_Return': 'Idiosyncratic (Alpha)'},\n",
    "                                      trendline=\"ols\")\n",
    "                fig_corr.update_layout(xaxis_tickformat=\".1%\", yaxis_tickformat=\".1%\")\n",
    "                st.plotly_chart(fig_corr, use_container_width=True)\n",
    "\n",
    "            # --- ENHANCED SECTION: Pre & Post-Event Patterns ---\n",
    "            st.subheader(\"Pre & Post-Event Patterns (Anticipation & Drift)\")\n",
    "            \n",
    "            # --- Calculate Pre-event and Post-event data ---\n",
    "            drift_data = []\n",
    "            pre_event_data = []\n",
    "            for ev_df in all_events:\n",
    "                try:\n",
    "                    # Pre-event run-up\n",
    "                    pre_event_ret = ev_df[ev_df['Rel_Day'] < 0][selected_stock].sum()\n",
    "                    pre_event_data.append({'Event': ev_df['Event_ID'].iloc[0], 'Pre-Event Run-up': pre_event_ret})\n",
    "\n",
    "                    # Post-event drift\n",
    "                    t1_close = ev_df[ev_df['Rel_Day'] == 1][selected_stock].values[0]\n",
    "                    drift_ret = ev_df[(ev_df['Rel_Day'] > 1) & (ev_df['Rel_Day'] <= window_size)][selected_stock].sum()\n",
    "                    drift_data.append({'Event': ev_df['Event_ID'].iloc[0], 'T+1 Move': t1_close, 'Drift (T+1 to End)': drift_ret})\n",
    "                except:\n",
    "                    continue\n",
    "            \n",
    "            col_pre, col_post = st.columns(2)\n",
    "\n",
    "            with col_pre:\n",
    "                # --- 1. Pre-Earnings Anticipation ---\n",
    "                st.markdown(\"**Pre-Earnings Anticipation**\")\n",
    "                if pre_event_data:\n",
    "                    pre_event_df = pd.DataFrame(pre_event_data)\n",
    "                    fig_pre_event = px.box(pre_event_df, y='Pre-Event Run-up', points=\"all\",\n",
    "                                           title=f\"Distribution of Pre-Event Run-up (T-{window_size} to T-1)\")\n",
    "                    fig_pre_event.update_layout(yaxis_tickformat=\".1%\")\n",
    "                    st.plotly_chart(fig_pre_event, use_container_width=True)\n",
    "\n",
    "            with col_post:\n",
    "                # --- 2. Conditional Post-Earnings Drift ---\n",
    "                st.markdown(\"**Conditional Post-Earnings Drift**\")\n",
    "                if drift_data:\n",
    "                    drift_df = pd.DataFrame(drift_data)\n",
    "                    pos_t1_drift = drift_df[drift_df['T+1 Move'] > 0]['Drift (T+1 to End)'].mean()\n",
    "                    neg_t1_drift = drift_df[drift_df['T+1 Move'] < 0]['Drift (T+1 to End)'].mean()\n",
    "\n",
    "                    drift_analysis_df = pd.DataFrame({\n",
    "                        \"Condition\": [\"After Positive T+1 Move\", \"After Negative T+1 Move\"],\n",
    "                        \"Average Drift\": [pos_t1_drift, neg_t1_drift]\n",
    "                    })\n",
    "                    fig_cond_drift = px.bar(drift_analysis_df, x=\"Condition\", y=\"Average Drift\",\n",
    "                                            color=\"Condition\", title=f\"Avg. Drift (T+2 to T+{window_size})\")\n",
    "                    fig_cond_drift.update_layout(yaxis_tickformat=\".2%\")\n",
    "                    st.plotly_chart(fig_cond_drift, use_container_width=True)\n",
    "\n",
    "            # --- Original PEAD Scatter Plot for context ---\n",
    "            if drift_data:\n",
    "                drift_df = pd.DataFrame(drift_data)\n",
    "                fig_drift = px.scatter(drift_df, x='T+1 Move', y='Drift (T+1 to End)', \n",
    "                                       hover_name='Event',\n",
    "                                       title=f\"Price Drift (Days +2 to +{window_size}) vs. Initial Reaction (Day +1)\",\n",
    "                                       labels={'T+1 Move': 'Initial Reaction (T+1)', 'Drift (T+1 to End)': f'Subsequent Drift (Next {window_size-1} Days)'})\n",
    "                fig_drift.add_hline(y=0, line_dash=\"dash\", line_color=\"gray\")\n",
    "                fig_drift.add_vline(x=0, line_dash=\"dash\", line_color=\"gray\")\n",
    "                fig_drift.update_layout(xaxis_tickformat=\".1%\", yaxis_tickformat=\".1%\")\n",
    "                st.plotly_chart(fig_drift, use_container_width=True)\n",
    "                st.caption(\"Points in Top-Right/Bottom-Left quadrants indicate **Momentum** (Drift follows move). Top-Left/Bottom-Right indicate **Reversal**.\")\n",
    "\n",
    "            st.markdown(\"---\")\n",
    "            st.subheader(\"Historical Correlation with Risk Factors\")\n",
    "            st.caption(\"This chart shows the historical correlation between the stock's daily returns and the daily returns of each risk factor over the entire dataset.\")\n",
    "            \n",
    "            # Calculate correlations from the returns dataframe\n",
    "            if selected_stock in returns_df.columns:\n",
    "                factor_correlations = returns_df.corr(numeric_only=True)[selected_stock].drop(selected_stock).sort_values()\n",
    "                \n",
    "                fig_corr_bar = px.bar(\n",
    "                    factor_correlations, \n",
    "                    x=factor_correlations.values, \n",
    "                    y=factor_correlations.index, \n",
    "                    orientation='h',\n",
    "                    title=f\"Historical Correlation of {selected_stock} with Risk Factors\"\n",
    "                )\n",
    "                st.plotly_chart(fig_corr_bar, use_container_width=True)\n",
    "\n",
    "    # --- Tab 2: Comparison ---\n",
    "    with tab2:\n",
    "        st.header(f\"Compare Two {selected_stock} Earnings Events\")\n",
    "        comp_col1, comp_col2 = st.columns(2)\n",
    "        \n",
    "        default_idx_a = len(earnings_df)-1 if len(earnings_df) >= 1 else 0\n",
    "        default_idx_b = len(earnings_df)-2 if len(earnings_df) >= 2 else 0\n",
    "\n",
    "        # --- Event A Selection ---\n",
    "        with comp_col1:\n",
    "            date_a_str = st.selectbox(\"Event A\", earnings_df['Earnings Date'].dt.strftime('%Y-%m-%d'), index=default_idx_a, key=\"comp_a\")\n",
    "            date_a = pd.to_datetime(date_a_str)\n",
    "            t1_a = full_df[full_df['Date'] == date_a + pd.Timedelta(days=1)]\n",
    "            if not t1_a.empty:\n",
    "                st.plotly_chart(create_waterfall(t1_a.iloc[0], factor_cols, f\"Attribution: {date_a_str}\"), use_container_width=True)\n",
    "        \n",
    "        # --- Event B Selection ---\n",
    "        with comp_col2:\n",
    "            date_b_str = st.selectbox(\"Event B\", earnings_df['Earnings Date'].dt.strftime('%Y-%m-%d'), index=default_idx_b, key=\"comp_b\")\n",
    "            date_b = pd.to_datetime(date_b_str)\n",
    "            t1_b = full_df[full_df['Date'] == date_b + pd.Timedelta(days=1)]\n",
    "            if not t1_b.empty:\n",
    "                st.plotly_chart(create_waterfall(t1_b.iloc[0], factor_cols, f\"Attribution: {date_b_str}\"), use_container_width=True)\n",
    "\n",
    "        st.markdown(\"---\")\n",
    "\n",
    "        # --- ADDED: Metrics Comparison Table ---\n",
    "        st.subheader(\"Key Metrics Comparison (T+1)\")\n",
    "        if not t1_a.empty and not t1_b.empty:\n",
    "            row_a = t1_a.iloc[0]\n",
    "            row_b = t1_b.iloc[0]\n",
    "            \n",
    "            alpha_pct_a = (row_a['Idiosyncratic_Return'] / row_a[selected_stock]) if row_a[selected_stock] != 0 else 0\n",
    "            alpha_pct_b = (row_b['Idiosyncratic_Return'] / row_b[selected_stock]) if row_b[selected_stock] != 0 else 0\n",
    "\n",
    "            comp_data = {\n",
    "                \"Metric\": [\"Total Return\", \"Idiosyncratic (Alpha) Return\", \"Factor-driven Return\", \"Alpha as % of Total\"],\n",
    "                f\"Event A ({date_a_str})\": [f\"{row_a[selected_stock]:.2%}\", f\"{row_a['Idiosyncratic_Return']:.2%}\", f\"{row_a['Factor_Return']:.2%}\", f\"{alpha_pct_a:.1%}\"],\n",
    "                f\"Event B ({date_b_str})\": [f\"{row_b[selected_stock]:.2%}\", f\"{row_b['Idiosyncratic_Return']:.2%}\", f\"{row_b['Factor_Return']:.2%}\", f\"{alpha_pct_b:.1%}\"]\n",
    "            }\n",
    "            st.dataframe(pd.DataFrame(comp_data), use_container_width=True, hide_index=True)\n",
    "\n",
    "        # --- ADDED: Cumulative Return Window Comparison ---\n",
    "        st.subheader(\"Cumulative Return Window Comparison\")\n",
    "        window_a = get_event_window(full_df, date_a, window_size)\n",
    "        window_b = get_event_window(full_df, date_b, window_size)\n",
    "\n",
    "        if window_a is not None and window_b is not None:\n",
    "            # Calculate cumulative returns for each window\n",
    "            window_a['Cumulative Return'] = window_a[selected_stock].cumsum()\n",
    "            window_b['Cumulative Return'] = window_b[selected_stock].cumsum()\n",
    "\n",
    "            # Combine for plotting\n",
    "            window_a['Event'] = f\"Event A ({date_a_str})\"\n",
    "            window_b['Event'] = f\"Event B ({date_b_str})\"\n",
    "            combined_windows = pd.concat([window_a, window_b])\n",
    "\n",
    "            fig_cum_comp = px.line(combined_windows, x='Rel_Day', y='Cumulative Return', color='Event',\n",
    "                                   title=\"Cumulative Performance During Event Windows\",\n",
    "                                   labels={'Rel_Day': 'Days Relative to Earnings', 'Cumulative Return': 'Cumulative Stock Return'})\n",
    "            fig_cum_comp.add_vline(x=0, line_dash=\"dash\", line_color=\"gray\", annotation_text=\"Announcement\")\n",
    "            st.plotly_chart(fig_cum_comp, use_container_width=True)\n",
    "\n",
    "    # --- Tab 3: Individual Deep Dive (Enhanced) ---\n",
    "    with tab3:\n",
    "        st.header(f\"Individual Deep Dive: {selected_stock} - {selected_date}\")\n",
    "        event_window = get_event_window(full_df, selected_date_dt, window_size)\n",
    "        \n",
    "        if event_window is not None:\n",
    "            t_plus_1 = event_window[event_window['Rel_Day'] == 1]\n",
    "            \n",
    "            if not t_plus_1.empty:\n",
    "                row = t_plus_1.iloc[0]\n",
    "                \n",
    "                # 1. Return Attribution Waterfall\n",
    "                st.subheader(f\"1. Return Attribution (T+1)\")\n",
    "                st.plotly_chart(create_waterfall(row, factor_cols, \"\"), use_container_width=True)\n",
    "\n",
    "                # 2. Top Contributors Text\n",
    "                all_contribs = {col: row[f'Contrib_{col}'] for col in factor_cols}\n",
    "                all_contribs['Idiosyncratic'] = row['Idiosyncratic_Return']\n",
    "                sorted_contribs = sorted(all_contribs.items(), key=lambda x: x[1], reverse=True)\n",
    "                \n",
    "                col_d1, col_d2 = st.columns(2)\n",
    "                with col_d1:\n",
    "                    st.markdown(\"**Top Positive Drivers:**\")\n",
    "                    for k, v in [i for i in sorted_contribs if i[1] > 0][:3]:\n",
    "                        st.write(f\"- {k}: `{v:.2%}`\")\n",
    "                with col_d2:\n",
    "                    st.markdown(\"**Top Negative Drivers:**\")\n",
    "                    for k, v in [i for i in reversed(sorted_contribs) if i[1] < 0][:3]:\n",
    "                        st.write(f\"- {k}: `{v:.2%}`\")\n",
    "\n",
    "                st.markdown(\"---\")\n",
    "\n",
    "                # 3. Historical Context Histogram (New Feature)\n",
    "                st.subheader(\"2. Historical Context\")\n",
    "                col_h1, col_h2 = st.columns([2, 1])\n",
    "                \n",
    "                with col_h1:\n",
    "                    fig_hist = px.histogram(full_df, x=selected_stock, nbins=100, title=\"Distribution of All Historical Daily Returns\",\n",
    "                                            labels={selected_stock: 'Daily Return'})\n",
    "                    fig_hist.add_vline(x=row[selected_stock], line_dash=\"dash\", line_color=\"red\", \n",
    "                                       annotation_text=f\"Event: {row[selected_stock]:.2%}\")\n",
    "                    st.plotly_chart(fig_hist, use_container_width=True)\n",
    "                \n",
    "                with col_h2:\n",
    "                    percentile = (full_df[selected_stock] < row[selected_stock]).mean() * 100\n",
    "                    st.info(f\"The T+1 return of **{row[selected_stock]:.2%}** is in the **{percentile:.1f}th percentile** of all daily returns since Sept 2022.\")\n",
    "\n",
    "                st.markdown(\"---\")\n",
    "\n",
    "                # 4. Factor Exposure Evolution (New Feature)\n",
    "                st.subheader(\"3. Factor Beta Evolution (Risk Exposure)\")\n",
    "                top_factors = [x[0] for x in sorted(all_contribs.items(), key=lambda x: abs(x[1]), reverse=True) if x[0] != 'Idiosyncratic'][:5]\n",
    "                selected_factors = st.multiselect(\"Select Factors to View Betas:\", factor_cols, default=top_factors)\n",
    "                \n",
    "                if selected_factors:\n",
    "                    loading_cols = [f\"{f}_Load\" for f in selected_factors]\n",
    "                    fig_load = px.line(event_window, x='Rel_Day', y=loading_cols, \n",
    "                                       title=\"Factor Loadings (Betas) During Event Window\",\n",
    "                                       labels={'value': 'Beta', 'Rel_Day': 'Days Relative to Earnings'})\n",
    "                    fig_load.add_vline(x=0, line_dash=\"dash\", line_color=\"white\", annotation_text=\"Announcement\")\n",
    "                    st.plotly_chart(fig_load, use_container_width=True)\n",
    "\n",
    "                st.markdown(\"---\")\n",
    "                \n",
    "                # --- 5. Volatility Context (GARCH Implementation) ---\n",
    "                st.subheader(\"4. Volatility Context\")\n",
    "                \n",
    "                # Get returns history before the event day\n",
    "                pre_event_returns = full_df[full_df['Date'] < row['Date']][selected_stock]\n",
    "                \n",
    "                forecasted_vol, vol_method = get_garch_forecast(pre_event_returns)\n",
    "                sigma_move = abs(row[selected_stock] / forecasted_vol) if forecasted_vol > 0 else 0\n",
    "                \n",
    "                col_v1, col_v2 = st.columns(2)\n",
    "                col_v1.metric(\"Forecasted Daily Volatility (T+1)\", f\"{forecasted_vol:.2%}\", help=f\"Volatility forecast using {vol_method}.\")\n",
    "                col_v2.metric(\"Sigma of T+1 Move\", f\"{sigma_move:.2f}x\", help=\"How many standard deviations the T+1 move was, based on the forecast.\")\n",
    "\n",
    "\n",
    "                with st.expander(\"View Raw Event Data\"):\n",
    "                    st.dataframe(event_window)\n",
    "                    \n",
    "                    # CSV Download Button\n",
    "                    csv = event_window.to_csv(index=False).encode('utf-8')\n",
    "                    st.download_button(\n",
    "                        label=\"ðŸ“¥ Download Event CSV\",\n",
    "                        data=csv,\n",
    "                        file_name=f\"{selected_stock}_event_{selected_date}.csv\",\n",
    "                        mime='text/csv',\n",
    "                    )\n",
    "\n",
    "    # --- Tab 4: AI Summary ---\n",
    "    with tab4:\n",
    "        st.header(f\"AI-Generated Analyst Summary for {selected_stock}\")\n",
    "\n",
    "        # Use session state to hold the summary\n",
    "        if 'ai_summary' not in st.session_state:\n",
    "            st.session_state.ai_summary = None\n",
    "        if 'summary_stock' not in st.session_state:\n",
    "            st.session_state.summary_stock = None\n",
    "\n",
    "        if st.button(\"Generate Report\"):\n",
    "            if not api_key:\n",
    "                st.warning(\"Please enter an API Key in the sidebar.\")\n",
    "                st.session_state.ai_summary = None # Clear previous summary\n",
    "            else:\n",
    "                # Prepare data\n",
    "                reaction_days = combined_events[combined_events['Rel_Day'] == 1]\n",
    "                \n",
    "                # Get latest and second latest event data\n",
    "                latest_event_date = earnings_df['Earnings Date'].max()\n",
    "                latest_reaction = full_df[full_df['Date'] == latest_event_date + pd.Timedelta(days=1)]\n",
    "                \n",
    "                second_latest_event_date = earnings_df['Earnings Date'].nlargest(2).iloc[-1] if len(earnings_df) > 1 else None\n",
    "                second_latest_reaction = full_df[full_df['Date'] == second_latest_event_date + pd.Timedelta(days=1)] if second_latest_event_date else pd.DataFrame()\n",
    "                \n",
    "                if not latest_reaction.empty:\n",
    "                    with st.spinner(\"Analyzing...\"):\n",
    "                        st.session_state.ai_summary = generate_ai_summary(api_key, selected_stock, full_df, reaction_days, latest_reaction, second_latest_reaction, factor_cols, combined_events)\n",
    "                        st.session_state.summary_stock = selected_stock # Store which stock this summary is for\n",
    "                else:\n",
    "                    st.error(\"No data available for the most recent earnings date.\")\n",
    "                    st.session_state.ai_summary = None\n",
    "\n",
    "        # Display the summary and download button if it exists for the current stock\n",
    "        if st.session_state.ai_summary and st.session_state.summary_stock == selected_stock:\n",
    "            st.markdown(\"---\")\n",
    "            st.markdown(st.session_state.ai_summary)\n",
    "            st.download_button(\n",
    "                label=\"ðŸ“¥ Download Summary\",\n",
    "                data=st.session_state.ai_summary,\n",
    "                file_name=f\"AI_Summary_{selected_stock}_{pd.Timestamp.now().strftime('%Y%m%d')}.txt\",\n",
    "                mime=\"text/plain\",\n",
    "            )\n",
    "\n",
    "    # --- Tab 5: Factor Performance ---\n",
    "    with tab5:\n",
    "        st.header(\"Historical Risk Factor Performance\")\n",
    "        st.markdown(\"Analyze the cumulative performance and relationships of the underlying risk factors.\")\n",
    "\n",
    "        # --- Section 1: Cumulative Performance vs. Stock ---\n",
    "        st.subheader(\"1. Cumulative Performance Comparison\")\n",
    "        default_factors = ['Market', 'Semiconductors', 'Value']\n",
    "        default_factors = [f for f in default_factors if f in factor_cols]\n",
    "\n",
    "        selected_factors_perf = st.multiselect(\"Select factors to plot:\", factor_cols, default=default_factors, key=\"factor_perf_select\")\n",
    "        compare_with_stock = st.checkbox(f\"Compare with {selected_stock}\", value=True)\n",
    "\n",
    "        if selected_factors_perf or compare_with_stock:\n",
    "            cols_to_plot = selected_factors_perf[:]\n",
    "            if compare_with_stock:\n",
    "                cols_to_plot.append(selected_stock)\n",
    "            \n",
    "            # Calculate cumulative returns from the original returns_df\n",
    "            perf_df = returns_df[['Date'] + cols_to_plot].copy()\n",
    "            perf_df[cols_to_plot] = perf_df[cols_to_plot].cumsum()\n",
    "\n",
    "            fig_factor_perf = px.line(perf_df, x='Date', y=cols_to_plot, title=\"Cumulative Performance: Factors vs. Stock\")\n",
    "            st.plotly_chart(fig_factor_perf, use_container_width=True)\n",
    "\n",
    "        st.markdown(\"---\")\n",
    "\n",
    "        # --- Section 2: Factor Correlation Matrix ---\n",
    "        st.subheader(\"2. Factor Correlation Matrix\")\n",
    "        st.caption(\"This heatmap shows which risk factors tend to move together (high positive correlation, dark red) or in opposite directions (high negative correlation, dark blue).\")\n",
    "        \n",
    "        # Calculate correlation on the factor returns\n",
    "        factor_return_cols = [f for f in returns_df.columns if f in factor_cols]\n",
    "        factor_corr = returns_df[factor_return_cols].corr()\n",
    "\n",
    "        fig_corr_heatmap = px.imshow(factor_corr, text_auto=\".2f\", aspect=\"auto\",\n",
    "                                     color_continuous_scale='RdBu_r', range_color=[-1, 1],\n",
    "                                     title=\"Historical Correlation Between Risk Factors\")\n",
    "        st.plotly_chart(fig_corr_heatmap, use_container_width=True)\n",
    "        \n",
    "        # --- Section 3: Z-Score Normalized View ---\n",
    "        if z_score_view:\n",
    "            st.markdown(\"---\")\n",
    "            st.subheader(\"3. Z-Score Normalized Factor Returns\")\n",
    "            st.caption(\"This chart shows each factor's daily return as a Z-score (number of standard deviations from its own mean). It helps identify days with unusually large moves across multiple factors on a comparable scale.\")\n",
    "            \n",
    "            z_score_df = returns_df[['Date']].copy()\n",
    "            for col in factor_return_cols:\n",
    "                z_score_df[col] = (returns_df[col] - returns_df[col].mean()) / returns_df[col].std()\n",
    "            \n",
    "            selected_z_factors = st.multiselect(\"Select factors to view Z-Scores:\", factor_return_cols, default=default_factors, key=\"z_score_select\")\n",
    "            if selected_z_factors:\n",
    "                fig_z_score = px.line(z_score_df, x='Date', y=selected_z_factors, title=\"Z-Score of Daily Factor Returns\")\n",
    "                st.plotly_chart(fig_z_score, use_container_width=True)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kr_capital",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
